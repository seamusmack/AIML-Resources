{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":101849,"databundleVersionId":13093295,"sourceType":"competition"},{"sourceId":12558437,"sourceType":"datasetVersion","datasetId":7929915}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\n\nprint(\"PHOENIX V20 FOUNDATION VALIDATION\")\nprint(\"=\" * 50)\n\nprint(\"Available input directories:\")\nfor item in os.listdir('/kaggle/input'):\n    print(f\"  {item}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T11:53:54.887148Z","iopub.execute_input":"2025-07-29T11:53:54.887334Z","iopub.status.idle":"2025-07-29T11:53:55.197406Z","shell.execute_reply.started":"2025-07-29T11:53:54.887317Z","shell.execute_reply":"2025-07-29T11:53:55.196683Z"}},"outputs":[{"name":"stdout","text":"PHOENIX V20 FOUNDATION VALIDATION\n==================================================\nAvailable input directories:\n  ariel-data-challenge-2025\n  ariel-2025-regenerated-core-files\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"## Cell 2\nimport pandas as pd\nimport os\n\ntest_root = '/kaggle/input/ariel-data-challenge-2025/test'\nexample_id = '1103775'  # or whichever test planet you want to analyze\n\nsignal_path = os.path.join(test_root, example_id, 'AIRS-CH0_signal_0.parquet')\nairs_data = pd.read_parquet(signal_path)\n\nprint(f\"Loaded spectrum for test ID {example_id}, shape: {airs_data.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T12:47:49.723810Z","iopub.execute_input":"2025-07-29T12:47:49.724070Z","iopub.status.idle":"2025-07-29T12:47:53.032611Z","shell.execute_reply.started":"2025-07-29T12:47:49.724047Z","shell.execute_reply":"2025-07-29T12:47:53.031891Z"}},"outputs":[{"name":"stdout","text":"Loaded spectrum for test ID 1103775, shape: (11250, 11392)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\n\ntest_root = '/kaggle/input/ariel-data-challenge-2025/test'\ntest_ids = sorted(os.listdir(test_root))\n\nprint(f\"Number of test spectra: {len(test_ids)}\")\nprint(f\"Sample test IDs: {test_ids[:5]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T12:49:46.270808Z","iopub.execute_input":"2025-07-29T12:49:46.271478Z","iopub.status.idle":"2025-07-29T12:49:46.279716Z","shell.execute_reply.started":"2025-07-29T12:49:46.271453Z","shell.execute_reply":"2025-07-29T12:49:46.278892Z"}},"outputs":[{"name":"stdout","text":"Number of test spectra: 1\nSample test IDs: ['1103775']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"## Cell 3\n\nimport os\nimport pandas as pd\nimport numpy as np\n\ndef extract_transit_spectrum(airs_data, transit_start=5200, transit_end=6600):\n    transit_depths = []\n    uncertainties = []\n\n    # Process in chunks for speed (optional)\n    for i in range(0, airs_data.shape[1], 1000):\n        for pixel_idx in range(i, min(i+1000, airs_data.shape[1])):\n            pixel_name = f'column_{pixel_idx}'\n            pixel_data = airs_data[pixel_name].values\n\n            # Baseline flux (out of transit)\n            out_flux_1 = pixel_data[1000:3000].mean()\n            out_flux_2 = pixel_data[8000:10000].mean()\n            baseline_flux = (out_flux_1 + out_flux_2) / 2\n\n            # Transit flux (minimum during transit)\n            transit_flux = pixel_data[transit_start:transit_end].min()\n\n            # Transit depth (normalized)\n            depth = (baseline_flux - transit_flux) / baseline_flux\n\n            # Simple uncertainty estimate\n            baseline_std = np.std(np.concatenate([pixel_data[1000:3000], pixel_data[8000:10000]]))\n            uncertainty = baseline_std / baseline_flux\n\n            transit_depths.append(depth)\n            uncertainties.append(uncertainty)\n\n    return np.array(transit_depths), np.array(uncertainties)\n\n\ntest_root = '/kaggle/input/ariel-data-challenge-2025/test'\ntest_ids = sorted(os.listdir(test_root))\n\ntest_depths = []\ntest_uncertainties = []\n\nfor tid in test_ids:\n    signal_path = os.path.join(test_root, tid, 'AIRS-CH0_signal_0.parquet')\n    airs_data = pd.read_parquet(signal_path)\n    \n    depths, uncerts = extract_transit_spectrum(airs_data)\n    test_depths.append(depths)\n    test_uncertainties.append(uncerts)\n\nprint(\"Extraction complete.\")\nprint(f\"Number of test spectra processed: {len(test_ids)}\")\nprint(\"Example pixel depths:\", test_depths[0][:10])\nprint(\"Example uncertainties:\", test_uncertainties[0][:10])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T12:53:37.221758Z","iopub.execute_input":"2025-07-29T12:53:37.222503Z","iopub.status.idle":"2025-07-29T12:53:39.261246Z","shell.execute_reply.started":"2025-07-29T12:53:37.222476Z","shell.execute_reply":"2025-07-29T12:53:39.260640Z"}},"outputs":[{"name":"stdout","text":"Extraction complete.\nNumber of test spectra processed: 1\nExample pixel depths: [0.04477639 0.04445791 0.04224326 0.04287321 0.06046482 0.03967913\n 0.05343237 0.04467901 0.03792467 0.04500336]\nExample uncertainties: [0.01302257 0.01294736 0.01293013 0.01392872 0.01718165 0.01428068\n 0.01624656 0.01327183 0.01238646 0.01227604]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"## Cell 4\n\nprint(\"IMPROVED SPECTRAL EXTRACTION:\")\nprint(\"-\" * 40)\n\ntransit_start = 5200  # Before minimum\ntransit_end = 6600    # After minimum\n\n# More sophisticated approach\nimproved_depths = []\nimproved_uncertainties = []\n\n\nprint(\"Using robust statistics and outlier rejection...\")\n\nfor pixel_idx in range(0, min(1000, airs_data.shape[1])):  # Test on first 1000 pixels\n    pixel_name = f'column_{pixel_idx}'\n    pixel_data = airs_data[pixel_name].values\n    \n    # Robust baseline using median\n    out_flux_1 = np.median(pixel_data[1000:3000])\n    out_flux_2 = np.median(pixel_data[8000:10000]) \n    baseline_flux = (out_flux_1 + out_flux_2) / 2\n    \n    # Robust transit depth using median of transit window (not minimum)\n    transit_flux = np.median(pixel_data[transit_start:transit_end])\n    \n    # Calculate depth\n    depth = (baseline_flux - transit_flux) / baseline_flux\n    \n    # Better uncertainty: photon noise + systematic\n    baseline_combined = np.concatenate([pixel_data[1000:3000], pixel_data[8000:10000]])\n    baseline_rms = np.std(baseline_combined)\n    photon_noise = np.sqrt(baseline_flux) / baseline_flux  # Poisson limit\n    systematic_noise = baseline_rms / baseline_flux\n    total_uncertainty = np.sqrt(photon_noise**2 + systematic_noise**2)\n    \n    # Reject obviously bad pixels\n    if 0.001 < depth < 0.5 and total_uncertainty < 0.1:  # Reasonable bounds\n        improved_depths.append(depth)\n        improved_uncertainties.append(total_uncertainty)\n\nprint(f\"\\nImproved results:\")\nprint(f\"  Good pixels: {len(improved_depths)}/{1000}\")\nprint(f\"  Transit depth range: {np.min(improved_depths)*100:.2f}% to {np.max(improved_depths)*100:.2f}%\")\nprint(f\"  Mean uncertainty: {np.mean(improved_uncertainties)*100:.3f}%\")\nprint(f\"  Median uncertainty: {np.median(improved_uncertainties)*100:.3f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T12:58:58.035722Z","iopub.execute_input":"2025-07-29T12:58:58.036013Z","iopub.status.idle":"2025-07-29T12:58:58.208315Z","shell.execute_reply.started":"2025-07-29T12:58:58.035994Z","shell.execute_reply":"2025-07-29T12:58:58.207739Z"}},"outputs":[{"name":"stdout","text":"IMPROVED SPECTRAL EXTRACTION:\n----------------------------------------\nUsing robust statistics and outlier rejection...\n\nImproved results:\n  Good pixels: 225/1000\n  Transit depth range: 0.11% to 0.50%\n  Mean uncertainty: 5.345%\n  Median uncertainty: 5.177%\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"## Cell 4a\n\ndef weighted_depth(depths, uncertainties):\n    \"\"\"\n    Computes a weighted average of transit depths using inverse-variance weighting.\n    Returns a single scalar prediction.\n    \"\"\"\n    weights = 1.0 / (uncertainties**2 + 1e-8)  # add epsilon to prevent div by zero\n    weighted_avg = np.sum(depths * weights) / np.sum(weights)\n    return weighted_avg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:12:21.809389Z","iopub.execute_input":"2025-07-29T13:12:21.809704Z","iopub.status.idle":"2025-07-29T13:12:21.813929Z","shell.execute_reply.started":"2025-07-29T13:12:21.809681Z","shell.execute_reply":"2025-07-29T13:12:21.813282Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"## Cell 4b\n\nsubmission_rows = []\n\nfor i in range(len(test_ids)):\n    pred = weighted_depth(improved_depths[i], improved_uncertainties[i])\n    submission_rows.append((test_ids[i], pred))\n\nprint(f\"Prediction loop complete: {len(submission_rows)} entries created.\")\nprint(\"Sample submission rows:\", submission_rows[:3])\n\nsubmission = pd.DataFrame(submission_rows, columns=[\"ID\", \"transit_depth\"])\n\nprint(\"Submission columns:\", submission.columns.tolist())\nprint(\"Submission shape:\", submission.shape)\nprint(\"Null values per column:\\n\", submission.isnull().sum())\nprint(\"Any infinite values in `transit_depth`:\", (~np.isfinite(submission['transit_depth'])).any())\nprint(\"Sample submission rows:\\n\", submission.head())\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file saved as 'submission.csv'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:12:24.909372Z","iopub.execute_input":"2025-07-29T13:12:24.909735Z","iopub.status.idle":"2025-07-29T13:12:24.937391Z","shell.execute_reply.started":"2025-07-29T13:12:24.909709Z","shell.execute_reply":"2025-07-29T13:12:24.936803Z"}},"outputs":[{"name":"stdout","text":"Prediction loop complete: 1 entries created.\nSample submission rows: [('1103775', 0.002288329519450801)]\nSubmission columns: ['ID', 'transit_depth']\nSubmission shape: (1, 2)\nNull values per column:\n ID               0\ntransit_depth    0\ndtype: int64\nAny infinite values in `transit_depth`: False\nSample submission rows:\n         ID  transit_depth\n0  1103775       0.002288\nSubmission file saved as 'submission.csv'\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"## Cell 5\n\nprint(\"FINDING PRECISE TRANSIT TIMING:\")\nprint(\"-\" * 40)\n\n# Find the exact transit duration by looking at flux evolution\n# Average across many pixels to reduce noise\nmean_flux_evolution = airs_data[['column_1000', 'column_2000', 'column_3000', 'column_4000', 'column_5000']].mean(axis=1)\n\n# Look at the flux in our suspected transit window\ntransit_window = mean_flux_evolution[transit_start:transit_end]\nwindow_steps = np.arange(transit_start, transit_end)\n\n# Find the baseline within this window - CORRECTED\nbaseline_segment_1 = mean_flux_evolution[1000:3000]\nbaseline_segment_2 = mean_flux_evolution[8000:10000]\nbaseline_combined = np.concatenate([baseline_segment_1, baseline_segment_2])\nbaseline_level = np.median(baseline_combined)\n\n# Find points significantly below baseline (actual transit)\ntransit_threshold = baseline_level * 0.98  # 2% depth threshold\nin_transit_mask = transit_window < transit_threshold\n\n# Find continuous transit period\nin_transit_indices = window_steps[in_transit_mask]\n\nif len(in_transit_indices) > 0:\n    true_transit_start = in_transit_indices[0]\n    true_transit_end = in_transit_indices[-1]\n    transit_duration = true_transit_end - true_transit_start\n    \n    print(f\"Precise transit timing:\")\n    print(f\"  Start: step {true_transit_start}\")\n    print(f\"  End: step {true_transit_end}\")\n    print(f\"  Duration: {transit_duration} steps\")\n    print(f\"  Fraction of orbit: {transit_duration/11250*100:.1f}%\")\n    \n    # Show the difference\n    precise_transit_depth = (baseline_level - mean_flux_evolution[true_transit_start:true_transit_end].min()) / baseline_level\n    window_median_depth = (baseline_level - transit_window.median()) / baseline_level\n    \n    print(f\"\\nDepth comparison:\")\n    print(f\"  Using precise timing: {precise_transit_depth*100:.2f}%\")\n    print(f\"  Using window median: {window_median_depth*100:.2f}%\")\nelse:\n    print(\"No clear transit found - need to adjust threshold\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T23:49:42.514777Z","iopub.execute_input":"2025-07-24T23:49:42.515033Z","iopub.status.idle":"2025-07-24T23:49:42.535762Z","shell.execute_reply.started":"2025-07-24T23:49:42.515015Z","shell.execute_reply":"2025-07-24T23:49:42.534860Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Cell 6\n\nimport os\nimport pandas as pd\nimport numpy as np\n\n# --- Load spectrum for a test planet ---\ntest_root = '/kaggle/input/ariel-data-challenge-2025/test'\nexample_id = '1103775'  # Use your target test ID\n\nsignal_path = os.path.join(test_root, example_id, 'AIRS-CH0_signal_0.parquet')\nairs_data = pd.read_parquet(signal_path)\n\nprint(f\"Loaded spectrum for test ID {example_id}, shape: {airs_data.shape}\")\n\n# --- Define precise transit timing ---\nprecise_start = 5298\nprecise_end = 5398\n\nprint(f\"Using precise transit timing: {precise_start} to {precise_end}\")\n\n# --- Extract corrected depths and uncertainties ---\ncorrected_depths = []\ncorrected_uncertainties = []\n\nprint(\"Processing all pixels with correct transit timing...\")\n\nfor pixel_idx in range(0, airs_data.shape[1]):\n    pixel_name = f'column_{pixel_idx}'\n    pixel_data = airs_data[pixel_name].values\n    \n    # Baseline flux outside transit\n    baseline_combined = np.concatenate([pixel_data[1000:3000], pixel_data[8000:10000]])\n    baseline_flux = np.median(baseline_combined)\n    \n    # Transit flux using precise timing window\n    transit_flux = pixel_data[precise_start:precise_end].min()\n    \n    # Calculate transit depth\n    depth = (baseline_flux - transit_flux) / baseline_flux\n    \n    # Uncertainty estimate\n    baseline_rms = np.std(baseline_combined)\n    photon_noise = np.sqrt(baseline_flux) / baseline_flux\n    systematic_noise = baseline_rms / baseline_flux\n    total_uncertainty = np.sqrt(photon_noise**2 + systematic_noise**2)\n    \n    # Filter good pixels by depth and uncertainty\n    if 0.001 < depth < 0.5 and total_uncertainty < 0.1:\n        corrected_depths.append(depth)\n        corrected_uncertainties.append(total_uncertainty)\n\ncorrected_depths = np.array(corrected_depths)\ncorrected_uncertainties = np.array(corrected_uncertainties)\n\nprint(f\"Processed {len(corrected_depths)} good pixels.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T23:49:48.051090Z","iopub.execute_input":"2025-07-24T23:49:48.051404Z","iopub.status.idle":"2025-07-24T23:49:51.388062Z","shell.execute_reply.started":"2025-07-24T23:49:48.051380Z","shell.execute_reply":"2025-07-24T23:49:51.387243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Cell 7\n\nprint(\"APPLYING REALISTIC QUALITY CUTS & SNR WEIGHTING:\")\nprint(\"-\" * 50)\n\n# Exoplanet transit depth bounds (customize for comp tuning)\nDEPTH_MIN = 0.005      # 0.5%\nDEPTH_MAX = 0.08       # 8%\nUNCERTAINTY_MAX = 0.08 # 8%\n\nrealistic_depths = []\nrealistic_uncertainties = []\npixel_weights = []\nrejected_pixels = 0\n\nfor i, depth in enumerate(corrected_depths):\n    uncertainty = corrected_uncertainties[i]\n    # Only basic physical cuts; no hard SNR threshold\n    if (DEPTH_MIN < depth < DEPTH_MAX and uncertainty < UNCERTAINTY_MAX):\n        realistic_depths.append(depth)\n        realistic_uncertainties.append(uncertainty)\n        snr = depth / uncertainty\n        pixel_weights.append(max(snr, 0.01))  # never zero, never negative\n    else:\n        rejected_pixels += 1\n\nrealistic_depths = np.array(realistic_depths)\nrealistic_uncertainties = np.array(realistic_uncertainties)\npixel_weights = np.array(pixel_weights)\n\nprint(f\"REALISTIC SPECTRUM (WEIGHTED):\")\nprint(f\"  Good pixels: {len(realistic_depths)}\")\nprint(f\"  Rejected pixels: {rejected_pixels}\")\n\nif len(realistic_depths) == 0:\n    print(\"  [!] No good pixels after quality cuts. Review or relax thresholds.\")\nelse:\n    weighted_mean_depth = np.average(realistic_depths, weights=pixel_weights)\n    weighted_mean_uncertainty = np.average(realistic_uncertainties, weights=pixel_weights)\n    print(f\"  Weighted mean depth: {weighted_mean_depth*100:.2f}%\")\n    print(f\"  Weighted mean uncertainty: {weighted_mean_uncertainty*100:.3f}%\")\n    print(f\"  Pixel weight range: {pixel_weights.min():.2f} to {pixel_weights.max():.2f}\")\n\n    # Optional: check for structure across wavelength/pixel order\n    if len(realistic_depths) > 10:\n        pixel_positions = np.arange(len(realistic_depths))\n        correlation = np.corrcoef(pixel_positions, realistic_depths)[0,1]\n        print(f\"  Correlation with wavelength: {correlation:.3f}\")\n        print(f\"\\n  [OK] Looks like a realistic exoplanet atmospheric spectrum!\")\n    else:\n        print(\"\\n  [!] Too few good pixels – may need to relax cuts or debug upstream filters.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T23:49:57.570601Z","iopub.execute_input":"2025-07-24T23:49:57.570901Z","iopub.status.idle":"2025-07-24T23:49:57.604623Z","shell.execute_reply.started":"2025-07-24T23:49:57.570876Z","shell.execute_reply":"2025-07-24T23:49:57.603672Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Cell 8\n\nimport os\nimport pandas as pd\nimport numpy as np\n\ntest_root = '/kaggle/input/ariel-data-challenge-2025/test'\ntest_ids = sorted(os.listdir(test_root))\n\ntest_depths = []\ntest_uncertainties = []\n\nfor tid in test_ids:\n    # Load the main signal file for each spectrum\n    signal_path = os.path.join(test_root, tid, 'AIRS-CH0_signal_0.parquet')\n    signal_df = pd.read_parquet(signal_path)\n    # Each column is a pixel; take mean for depth, std for uncertainty\n    pixel_means = signal_df.mean(axis=0).values.astype(float)  # shape: (num_pixels,)\n    pixel_stds = signal_df.std(axis=0).values.astype(float)\n    test_depths.append(pixel_means)\n    test_uncertainties.append(pixel_stds)\n\nprint(\"Extraction complete.\")\nprint(\"Example pixel depths:\", test_depths[0][:10])\nprint(\"Example uncertainties:\", test_uncertainties[0][:10])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T23:50:05.966857Z","iopub.execute_input":"2025-07-24T23:50:05.967613Z","iopub.status.idle":"2025-07-24T23:50:07.768691Z","shell.execute_reply.started":"2025-07-24T23:50:05.967576Z","shell.execute_reply":"2025-07-24T23:50:07.767748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Cell 9\n\ndef weighted_depth(corrected_depths, corrected_uncertainties,\n                   depth_min=0.005, depth_max=0.08, uncertainty_max=0.08):\n    \"\"\"\n    Returns SNR-weighted mean depth for a single spectrum,\n    using only physically realistic pixels.\n    \"\"\"\n    realistic_depths = []\n    pixel_weights = []\n    for d, u in zip(corrected_depths, corrected_uncertainties):\n        if (depth_min < d < depth_max and u < uncertainty_max):\n            snr = d / u\n            pixel_weights.append(max(snr, 0.01))   # floor weight to avoid zeros\n            realistic_depths.append(d)\n    if not realistic_depths:\n        # Fallback: mean of ALL pixels if none pass physical cuts\n        return float(np.mean(corrected_depths))\n    realistic_depths = np.array(realistic_depths)\n    pixel_weights = np.array(pixel_weights)\n    return float(np.average(realistic_depths, weights=pixel_weights))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T23:58:46.875439Z","iopub.execute_input":"2025-07-24T23:58:46.876073Z","iopub.status.idle":"2025-07-24T23:58:46.881924Z","shell.execute_reply.started":"2025-07-24T23:58:46.876046Z","shell.execute_reply":"2025-07-24T23:58:46.880882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_rows = []\n\nfor i in range(len(test_ids)):\n    pred = weighted_depth(test_depths[i], test_uncertainties[i])\n    submission_rows.append((test_ids[i], pred))\n\nprint(f\"Prediction loop complete: {len(submission_rows)} entries created.\")\nprint(\"Sample submission rows:\", submission_rows[:3])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T23:59:11.044094Z","iopub.execute_input":"2025-07-24T23:59:11.044519Z","iopub.status.idle":"2025-07-24T23:59:11.052389Z","shell.execute_reply.started":"2025-07-24T23:59:11.044497Z","shell.execute_reply":"2025-07-24T23:59:11.051484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Cell 10\n\n# Create submission DataFrame from prediction results\nsubmission = pd.DataFrame(submission_rows, columns=[\"ID\", \"transit_depth\"])\n\n# Validate submission before saving\nprint(\"Submission columns:\", submission.columns.tolist())\nprint(\"Submission shape:\", submission.shape)\nprint(\"Null values per column:\\n\", submission.isnull().sum())\nprint(\"Any infinite values in 'transit_depth':\", ~np.isfinite(submission['transit_depth']).all())\nprint(\"Sample submission rows:\\n\", submission.head())\n\n# Save submission CSV file\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file saved as 'submission.csv'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T23:59:16.779546Z","iopub.execute_input":"2025-07-24T23:59:16.780045Z","iopub.status.idle":"2025-07-24T23:59:16.801628Z","shell.execute_reply.started":"2025-07-24T23:59:16.780022Z","shell.execute_reply":"2025-07-24T23:59:16.800770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 19: Submission sanity check\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nprint(\"Quick submission summary:\")\nprint(\"Shape:\", submission.shape)\nprint(\"First few rows:\\n\", submission.head())\n\nplt.hist(submission['transit_depth'], bins=50)\nplt.xlabel(\"Predicted Transit Depth\")\nplt.ylabel(\"Count\")\nplt.title(\"Submission Distribution\")\nplt.show()\n\n# Check for bad values\nprint(\"NaNs in submission:\", submission['transit_depth'].isna().sum())\nprint(\"Infs in submission:\", (~np.isfinite(submission['transit_depth'])).sum())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 20: Fallback usage diagnostics\n\nnum_fallbacks = 0\nfor i in range(len(test_ids)):\n    # Count if all pixels in a spectrum fail the physical cuts\n    use_fallback = not any(\n        (0.005 < d < 0.08 and u < 0.08)\n        for d, u in zip(test_depths[i], test_uncertainties[i])\n    )\n    if use_fallback:\n        num_fallbacks += 1\n\nprint(f\"Number of fallback predictions used: {num_fallbacks} out of {len(test_ids)}\")\nif num_fallbacks > 0:\n    print(\"Consider investigating spectra with all pixels outside physical range.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}